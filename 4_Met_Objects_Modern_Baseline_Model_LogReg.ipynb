{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a760bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5387b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4133873",
   "metadata": {},
   "outputs": [],
   "source": [
    "modern = pd.read_csv(\"modern_met_fe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fa283ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215649 entries, 0 to 215648\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                Non-Null Count   Dtype\n",
      "---  ------                                --------------   -----\n",
      " 0   highlighted                           215649 non-null  bool \n",
      " 1   obj_year                              215649 non-null  int64\n",
      " 2   department_drawings_and_prints        215649 non-null  int64\n",
      " 3   department_european_paintings         215649 non-null  int64\n",
      " 4   department_modern_and_cont_art        215649 non-null  int64\n",
      " 5   department_photographs                215649 non-null  int64\n",
      " 6   department_robert_lehman              215649 non-null  int64\n",
      " 7   department_libraries                  215649 non-null  int64\n",
      " 8   other_obj_name                        215649 non-null  int64\n",
      " 9   obj_name_painting                     215649 non-null  int64\n",
      " 10  obj_name_photo                        215649 non-null  int64\n",
      " 11  obj_name_print                        215649 non-null  int64\n",
      " 12  obj_name_sculpture                    215649 non-null  int64\n",
      " 13  obj_name_watercolor                   215649 non-null  int64\n",
      " 14  artist_role_author                    215649 non-null  int64\n",
      " 15  artist_role_other                     215649 non-null  int64\n",
      " 16  artist_role_publisher                 215649 non-null  int64\n",
      " 17  artist_nationality_bgdns              215649 non-null  int64\n",
      " 18  artist_nationality_french             215649 non-null  int64\n",
      " 19  artist_nationality_italian            215649 non-null  int64\n",
      " 20  artist_nationality_Other Nationality  215649 non-null  int64\n",
      " 21  medium_gelatin_silver_print           215649 non-null  int64\n",
      " 22  medium_illustrated_book               215649 non-null  int64\n",
      " 23  medium_marble                         215649 non-null  int64\n",
      " 24  medium_oil_on_canvas                  215649 non-null  int64\n",
      " 25  medium_oil_on_wood                    215649 non-null  int64\n",
      " 26  medium_other                          215649 non-null  int64\n",
      " 27  class_other                           215649 non-null  int64\n",
      " 28  class_paintings                       215649 non-null  int64\n",
      " 29  class_photographs                     215649 non-null  int64\n",
      " 30  class_prints                          215649 non-null  int64\n",
      " 31  class_sculpture                       215649 non-null  int64\n",
      "dtypes: bool(1), int64(31)\n",
      "memory usage: 51.2 MB\n"
     ]
    }
   ],
   "source": [
    "modern.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a99567cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    214899\n",
       "True        750\n",
       "Name: highlighted, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern.highlighted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9a8a41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0034778737670937494"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_ratio = len(modern[modern.highlighted])/len(modern)\n",
    "highlight_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2563a",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fd7bd",
   "metadata": {},
   "source": [
    "This model is being built for when the Met is accepting an object into its collection. As we have agreed on 'highligted' as our measure of visibility, a donor would want the piece to be definitely 'highlighted' if they are donating it to the museum indeed. \n",
    "\n",
    "Given the above scenariio, let's think about our confusion matrix/ what metrics we care about: \n",
    "- If we have a FN: our model predicts that a donated object will not be highlighted and it actually is. Well this is not horrible to be honest, if someone decides to donate even if the object is not going to be highlighted (GOOD FOR THEM, WE LOVE THEM! TRUE LOVER OF ARTS & CULTURE), then they'd be happily surpised to find out that it is highlighted. \n",
    "- On the other hand, if we have a FP: this is not so good about our model, after all we don't want to mislead a donor telling them this object will most likely be highlighted and then let them down by it not being highlighted. \n",
    "\n",
    "Given the above, our key metric in building this model will be *PRECISION*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29105cd9",
   "metadata": {},
   "source": [
    "### Baselining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37a9b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(modern.iloc[:, 1:], modern.iloc[:, 0], \n",
    "                                                    test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83973b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, max_iter=500000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100, solver='liblinear', max_iter=500000)\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84215db4",
   "metadata": {},
   "source": [
    "**Hard Predictions & Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6277e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_hard = logreg.predict(x_test)\n",
    "y_predict_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ce57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_confusion = confusion_matrix(y_test, y_predict_hard)\n",
    "logreg_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03406be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=80)\n",
    "sns.heatmap(logreg_confusion, annot=True, \\\n",
    "            xticklabels=['not','highlighted'], yticklabels=['not','highlighted'])\n",
    "plt.xlabel('Highlighting Predicted')\n",
    "plt.ylabel('Highlighting Actual')\n",
    "plt.title('Logreg Confusion Matrix: Modern Met')\n",
    "plt.savefig(\"Logreg Confusion Matrix for Modern Met.png\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1706e626",
   "metadata": {},
   "source": [
    "**Probability Predictions & Precision Recall Curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_prob =logreg.predict_proba(x_test)\n",
    "y_predict_prob = y_predict_prob[:, 1]\n",
    "y_predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29541bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_test, y_predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1077492",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=80)\n",
    "plt.plot(threshold_curve, precision_curve[1:],label='precision')\n",
    "plt.plot(threshold_curve, recall_curve[1:], label='recall')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Threshold (above this probability, label as highlight-possible)');\n",
    "plt.title('Precision and Recall Curves for Modern Met')\n",
    "plt.savefig(\"Precision and Recall Curves for Modern Met.png\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494de2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=80)\n",
    "plt.plot(recall_curve[1:], precision_curve[1:],label='precision')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve for Modern Met\")\n",
    "plt.savefig(\"Precision-Recall Curve for Modern Met.png\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb8c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db589fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=80)\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for predicting higlighting at the Met Modern Section')\n",
    "plt.savefig(\"ROC curve for predicting higlighting at the Met Modern Section.png\", bbox_inches='tight');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_test, y_predict_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e1f5b",
   "metadata": {},
   "source": [
    "**Scoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a08e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = logreg.score(x_train, y_train)\n",
    "test_score = logreg.score(x_test, y_test)\n",
    "print(f\"Train score: {train_score}, Test score: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_precision = precision_score(y_test, y_predict_hard)\n",
    "logreg_recall = recall_score(y_test, y_predict_hard)\n",
    "logreg_f1 = f1_score(y_test, y_predict_hard)\n",
    "print(f\"Precision score: {logreg_precision}, Recall score: {logreg_recall}, F1 score: {logreg_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_predict_prob)\n",
    "roc_auc_logreg = roc_auc_score(y_test, y_predict_prob)\n",
    "print(f\"ROC - AUC score: {roc_auc_logreg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022fc57",
   "metadata": {},
   "source": [
    "**Find Threshold for dealing with Class Imbalance (Manually)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_df = pd.DataFrame(logreg.predict_proba(x_test))\n",
    "print(y_pred_prob_df.iloc[:10, :])\n",
    "threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "for i in threshold_list:\n",
    "    print ('\\n******** For i = {} ******'.format(i))\n",
    "    Y_test_pred = y_pred_prob_df.applymap(lambda x: 1 if x>i else 0)\n",
    "    test_precision = precision_score(y_test, Y_test_pred.iloc[:,1])\n",
    "    print('Our testing precision is {}'.format(test_precision))\n",
    "\n",
    "    print(confusion_matrix(y_test, Y_test_pred.iloc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13816b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_df = pd.DataFrame(logreg.predict_proba(x_test))\n",
    "Y_test_pred = y_pred_prob_df.applymap(lambda x: 1 if x>0.334679 else 0)\n",
    "test_precision = precision_score(y_test, Y_test_pred.iloc[:,1])\n",
    "test_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12add57",
   "metadata": {},
   "source": [
    "**Class Imbalance (Plotting)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = x_test, y_test \n",
    "\n",
    "thresh_ps = np.linspace(.10,.50,1000)\n",
    "model_val_probs = logreg.predict_proba(X_val)[:,1] \n",
    "\n",
    "f1_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "for p in thresh_ps:\n",
    "    model_val_labels = model_val_probs >= p\n",
    "    f1_scores.append(f1_score(y_val, model_val_labels))    \n",
    "    prec_scores.append(precision_score(y_val, model_val_labels))\n",
    "    rec_scores.append(recall_score(y_val, model_val_labels))\n",
    "    acc_scores.append(accuracy_score(y_val, model_val_labels))\n",
    "    \n",
    "plt.plot(thresh_ps, f1_scores)\n",
    "plt.plot(thresh_ps, prec_scores)\n",
    "plt.plot(thresh_ps, rec_scores)\n",
    "plt.plot(thresh_ps, acc_scores)\n",
    "\n",
    "plt.title('Metric Scores vs. Positive Class Decision Probability Threshold')\n",
    "plt.legend(['F1','Precision','Recall','Accuracy'], bbox_to_anchor=(1.05, 0), loc='lower left')\n",
    "plt.xlabel('P threshold')\n",
    "plt.ylabel('Metric score')\n",
    "\n",
    "best_f1_score = np.max(f1_scores) \n",
    "best_prec_score = np.max(prec_scores)\n",
    "best_thresh_p = thresh_ps[np.argmax(prec_scores)]\n",
    "\n",
    "print('Logistic Regression Model best Precision score %.3f at prob decision threshold >= %.6f' \n",
    "      % (best_prec_score, best_thresh_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3de74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=80)\n",
    "sns.heatmap(logreg_confusion, annot=True, \\\n",
    "            xticklabels=['not','highlighted'], yticklabels=['not','highlighted'])\n",
    "plt.xlabel('Highlighting Predicted')\n",
    "plt.ylabel('Highlighting Actual')\n",
    "plt.title('Logreg Confusion Matrix: Modern Met')\n",
    "plt.savefig(\"Logreg Confusion Matrix for Modern Met.png\", bbox_inches='tight');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
